{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learn MNIST data set.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FCZBMVPPU5na"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t2wain/colab/blob/master/Learn_MNIST_data_set.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oVfh3gDPQg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCZBMVPPU5na",
        "colab_type": "text"
      },
      "source": [
        "# Inspecting data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkjcgVWmQMiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digits = datasets.load_digits()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAgiAhWIRtwy",
        "colab_type": "code",
        "outputId": "66a9c668-0106-4250-c38f-f38ecac4b8f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"data:\", digits.data.shape, type(digits.data))\n",
        "print(\"target:\", digits.target.shape, type(digits.target))\n",
        "print(\"target_names:\", digits.target_names.shape, type(digits.target_names))\n",
        "print(\"images:\", digits.images.shape, type(digits.images))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data: (1797, 64) <class 'numpy.ndarray'>\n",
            "target: (1797,) <class 'numpy.ndarray'>\n",
            "target_names: (10,) <class 'numpy.ndarray'>\n",
            "images: (1797, 8, 8) <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9BWnNASTpYh",
        "colab_type": "code",
        "outputId": "4be5fae4-d1ff-4a72-a88e-2ba3c9f4e3fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "images_and_labels = list(zip(digits.images, digits.target))\n",
        "for index, (image, label) in enumerate(images_and_labels[:10]):\n",
        "    plt.subplot(2, 5, index + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    plt.title('Training: %i' % label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADfCAYAAADWQznrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nW5IKY3BLUmEMbkkqjMEtSYX5f+JS8Lp4AVjOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y97UWz8OV3vb",
        "colab_type": "text"
      },
      "source": [
        "# Example 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii6ljKYDV65D",
        "colab_type": "text"
      },
      "source": [
        "## Utility methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Zm1II56Y3Dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_gen(X, Y=None, batch_size=1, epochs=1):\n",
        "  X_size, _ = X.shape\n",
        "\n",
        "  for ep in range(epochs):\n",
        "    for step in range(X_size // batch_size):\n",
        "      offset = (step * batch_size) % X_size\n",
        "      batch_x = X[offset:(offset + batch_size), :]\n",
        "      batch_y = None if Y is None else Y[offset:(offset + batch_size)]\n",
        "      yield (batch_x, batch_y)\n",
        "    remainder = X_size % batch_size\n",
        "    if remainder > 0:\n",
        "      offset = X_size - remainder\n",
        "      batch_x = X[offset:, :]\n",
        "      batch_y = None if Y is None else Y[offset:]\n",
        "      yield (batch_x, batch_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU4m55J7ln6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_dnn(num_features, num_labels, hiddens=[]):\n",
        "  \n",
        "  def loss(Y, y_prob):\n",
        "    xentropy = -tf.reduce_sum(Y * tf.log(y_prob), reduction_indices=1)\n",
        "    loss = tf.reduce_mean(xentropy, name='cost')\n",
        "    return loss\n",
        "\n",
        "\n",
        "  def loss_logit(Y, logit):\n",
        "    xentropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=Y)\n",
        "    loss = tf.reduce_mean(tf.reduce_sum(xentropy), name='cost')\n",
        "    #loss = tf.reduce_sum(xentropy, name='cost')\n",
        "    return loss\n",
        "\n",
        "\n",
        "  num_sample = None\n",
        "  with tf.name_scope('placeholders'):\n",
        "    Xin = tf.placeholder(tf.float32, shape=[num_sample, num_features], name='Xin')\n",
        "    Yin = tf.placeholder(tf.float32, shape=[num_sample, num_labels], name='Yin')\n",
        "    rate = tf.placeholder(tf.float32, name='dropout_rate')\n",
        "  \n",
        "  X = Xin; W = None; layers = []; y_out = None\n",
        "  # create nodes for hidden layers\n",
        "  num_input = num_features\n",
        "  num_hidden_layers = len(hiddens)\n",
        "\n",
        "  for layer_num, num_node_output in enumerate(hiddens):\n",
        "    layer_name = \"hidden_layer_%d\" % (layer_num+1)\n",
        "    with tf.name_scope(layer_name):\n",
        "      with tf.variable_scope(layer_name):\n",
        "        W = tf.get_variable('W', \n",
        "          initializer=tf.truncated_normal([num_input, num_node_output], stddev=0.1))\n",
        "        b = tf.get_variable('b', \n",
        "          initializer=tf.Variable(tf.constant(0.1,shape=[num_node_output])))\n",
        "      fx = tf.add(tf.matmul(X, W), b) # linear regression\n",
        "      y_out = tf.nn.relu6(fx) # activation funtion to introduce non-linearity\n",
        "      # apply dropout to hidden layer to introduce regularization of W\n",
        "      layer_drop = tf.nn.dropout(y_out, rate=rate, name='y_out')\n",
        "      y_out = layer_drop\n",
        "      # keeping track of each layer\n",
        "      layers.append({\"W\": W, \"b\": b, \"out\": y_out, \"W_val\": None, \"b_val\": None})\n",
        "      X = y_out # y become Xin to next layer\n",
        "      num_input = num_node_output\n",
        "  \n",
        "  # create output layer\n",
        "  num_input = num_features if W is None else num_input\n",
        "  num_node_output = num_labels\n",
        "  with tf.name_scope('output'):\n",
        "    with tf.variable_scope('output'):\n",
        "      W = tf.get_variable('W', \n",
        "        initializer=tf.truncated_normal([num_input, num_node_output], stddev=0.1))\n",
        "      b = tf.get_variable('b', \n",
        "        initializer=tf.constant(0.1,shape=[num_node_output]))\n",
        "    y_logit = tf.add(tf.matmul(X, W), b) # logistic regression, ln-odd\n",
        "    # convert to probability, exp-logit, and normalize to interval between 0 and 1\n",
        "    y_prob = tf.nn.softmax(y_logit, name='y_prob')\n",
        "    layers.append({\"W\": W, \"b\": b, \"out\": y_prob, \"W_val\": None, \"b_val\": None})\n",
        "    y_pred = tf.argmax(y_prob, 1, name='y_pred') # index of max probablity\n",
        "    y_label = tf.argmax(Yin, 1, name='y_label') # index of one-hot label\n",
        "\n",
        "  with tf.name_scope('optimize'):\n",
        "    cost = loss_logit(Yin, y_logit)\n",
        "    #cost = loss(Yin, y_prob)\n",
        "    op = tf.train.AdamOptimizer()\n",
        "    # minimize cost/loss\n",
        "    train_op = op.minimize(cost)\n",
        "  \n",
        "  with tf.name_scope('metrics'):\n",
        "    correct_prediction = tf.equal(y_pred, y_label)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"), name='accuracy')\n",
        "  \n",
        "  return {\"x\": Xin, \"y\": Yin, \"dropout_rate\": rate, \"layers\": layers, \n",
        "          \"cost\": cost, \"accuracy\": accuracy, \"y_prob\": y_prob, \"y_pred\": y_pred,\n",
        "          \"op\": op, \"train_op\": train_op}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E-Zi4LkjF_Gs",
        "colab": {}
      },
      "source": [
        "def build_classifier_estimator(num_features, num_labels, hiddens=[], msg_per_steps=0):\n",
        "  is_saved = False\n",
        "  \n",
        "  g1 = tf.Graph()\n",
        "  with g1.as_default() as graph:\n",
        "    dnn = build_dnn(num_features, num_labels, hiddens)\n",
        "\n",
        "  # placeholders, input to the training\n",
        "  X = dnn[\"x\"]\n",
        "  Y = dnn[\"y\"]\n",
        "  rate = dnn[\"dropout_rate\"]\n",
        "\n",
        "  # optimizer\n",
        "  op = dnn[\"op\"]\n",
        "  train_op = dnn[\"train_op\"]\n",
        "\n",
        "  # metrics\n",
        "  cost = dnn[\"cost\"]\n",
        "  accuracy = dnn[\"accuracy\"]\n",
        "  y_pred = dnn[\"y_pred\"]\n",
        "  y_prob = dnn[\"y_prob\"]\n",
        "  \n",
        "\n",
        "  def train(xsample, ysample,  batch_size=1, training_epochs=1, \n",
        "            learning_rate=0.001, dropout_rate=0, max_loss=0.01, limit_count=4):\n",
        "    op.learning_rate = learning_rate\n",
        "    loss_count = 0\n",
        "    with tf.Session(graph=g1) as sess:\n",
        "      _restoreVars(sess)\n",
        "      step_iterator = enumerate(data_gen(xsample, ysample,  batch_size, training_epochs))\n",
        "      for step, (batch_xs, batch_labels) in step_iterator:\n",
        "        feed_dict = {X: batch_xs, Y: batch_labels, rate: dropout_rate}\n",
        "        sess.run(train_op, feed_dict=feed_dict)\n",
        "\n",
        "        # print training progress\n",
        "        if msg_per_steps > 0 and step % msg_per_steps == 0:\n",
        "          feed_dict = {X: batch_xs, Y: batch_labels, rate: 0}\n",
        "          cost_val, accuracy_val = sess.run([cost, accuracy], feed_dict=feed_dict)\n",
        "          print(\n",
        "              \"Iteration\", str(step), \n",
        "              \"\\t| Loss =\", str(cost_val), \n",
        "              \"\\t| Accuracy =\", str(accuracy_val))\n",
        "          \n",
        "        # early training stop\n",
        "        if math.isnan(cost_val) or loss_count > limit_count:\n",
        "          break;\n",
        "        elif cost_val < max_loss:\n",
        "          loss_count += 1\n",
        "          \n",
        "      _saveVars(sess)\n",
        "\n",
        "      \n",
        "  def _restoreVars(sess):\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    if is_saved:\n",
        "      for layer in dnn[\"layers\"]:\n",
        "        sess.run(layer[\"W\"].assign(layer[\"W_val\"]))\n",
        "        sess.run(layer[\"b\"].assign(layer[\"b_val\"]))\n",
        "\n",
        "    \n",
        "  def _saveVars(sess):\n",
        "    nonlocal is_saved\n",
        "    is_saved = True\n",
        "    for layer in dnn[\"layers\"]:\n",
        "      layer[\"W_val\"] = sess.run(layer[\"W\"])\n",
        "      layer[\"b_val\"] = sess.run(layer[\"b\"])\n",
        "\n",
        "      \n",
        "  def evaluate(xsample, ysample, batch_size=1):\n",
        "    if not is_saved:\n",
        "      return \"Error: Training has not been done.\"\n",
        "\n",
        "    with tf.Session(graph=g1) as sess:\n",
        "      _restoreVars(sess)\n",
        "      cost_total = accuracy_total = step = 0\n",
        "      for step, (batch_xs, batch_ys) in enumerate(data_gen(xsample, ysample,  batch_size)):\n",
        "        feed_dict = {X: batch_xs, Y: batch_ys, rate: 0}\n",
        "        cost_val, accuracy_val = sess.run([cost, accuracy], feed_dict=feed_dict)\n",
        "        cost_total += cost_val\n",
        "        accuracy_total += accuracy_val\n",
        "      return (cost_val/(step+1), accuracy_total/(step+1))\n",
        "\n",
        "    \n",
        "  def predict(xdata, labels, batch_size=1):\n",
        "    if not is_saved:\n",
        "      return \"Error: Training has not been done.\"\n",
        "      \n",
        "    with tf.Session(graph=g1) as sess:\n",
        "      _restoreVars(sess)\n",
        "      pred = []; prob = []\n",
        "      for (batch_xs, _) in data_gen(xdata, batch_size=batch_size):\n",
        "        feed_dict={X: batch_xs, rate: 0}\n",
        "        yprob = sess.run(y_prob, feed_dict=feed_dict)\n",
        "        ypred = np.argmax(yprob, axis=1)\n",
        "        pred.extend(ypred)\n",
        "        prob.extend(yprob.round(3))\n",
        "        \n",
        "      df = pd.DataFrame(prob, columns=labels)\n",
        "      plabel = labels[pred]\n",
        "      df[\"ypred\"] = plabel\n",
        "      return df\n",
        "\n",
        "    \n",
        "  return (train, evaluate, predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAS37b0NfoIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot(labels, ydata):\n",
        "  y_target = np.expand_dims(ydata, axis=1)\n",
        "  enc = OneHotEncoder(categories=[labels])\n",
        "  enc.fit(y_target)\n",
        "  return (labels, enc.transform(y_target).toarray())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdTWTZuAWbAP",
        "colab_type": "text"
      },
      "source": [
        "## Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWHbAea6ns4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tensors_ex():\n",
        "  g1 = tf.Graph()\n",
        "  with g1.as_default() as graph:\n",
        "    dnn = build_dnn(3, 4, [2,2])\n",
        "    t = {\"x\": graph.get_tensor_by_name('placeholders/Xin:0'), \n",
        "        \"y\": graph.get_tensor_by_name('placeholders/Yin:0'), \n",
        "        \"dropout_rate\": graph.get_tensor_by_name('placeholders/dropout_rate:0'), \n",
        "        \"cost\": graph.get_tensor_by_name('optimize/cost:0'), \n",
        "        \"accuracy\": graph.get_tensor_by_name('metrics/accuracy:0'), \n",
        "        \"out\": graph.get_tensor_by_name('output/y_pred:0')}\n",
        "  return (dnn, t)\n",
        "\n",
        "\n",
        "get_tensors_ex()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaDLw1PCwJj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(nsample=None):\n",
        "  ds = datasets.load_digits()\n",
        "  \n",
        "  # build dataframe\n",
        "  df = pd.DataFrame(ds.data)\n",
        "  df[\"ydata\"] = ds.target\n",
        "  \n",
        "  # get subset of data\n",
        "  if not nsample==None:\n",
        "    df = df.sample(nsample)\n",
        "    \n",
        "  # normalization\n",
        "  df.iloc[:,:-1] = df.iloc[:,:-1].apply((lambda x: (x - x.mean()) / x.std()), axis=1)\n",
        "  \n",
        "  # one-hot encoding the target\n",
        "  y_labels, y_dummies = one_hot(ds.target_names, df[\"ydata\"].to_numpy())\n",
        "  dhot = pd.DataFrame(y_dummies, columns=y_labels)\n",
        "    \n",
        "  # split dataset into train and test\n",
        "  x_train, x_test, y_train, y_test = train_test_split(\n",
        "    df, dhot, test_size=0.3)\n",
        "\n",
        "  return (x_train, x_test, y_train, y_test, ds)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvbFTWk3WdHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ex(nsample=None):\n",
        "  batch_size = 128\n",
        "  learning_rate = 0.0001\n",
        "  hidden_layers = [256,256]\n",
        "  \n",
        "  (x_train_ds, x_test_ds, y_train_ds, y_test_ds, ds) = get_data()\n",
        "  x_train = x_train_ds.iloc[:,:-1].to_numpy()\n",
        "  x_test = x_test_ds.iloc[:,:-1].to_numpy()\n",
        "  y_train = y_train_ds.to_numpy()\n",
        "  y_test = y_test_ds.to_numpy()\n",
        "\n",
        "  train_size, num_features = x_train.shape\n",
        "  num_labels = ds.target_names.shape[0]\n",
        "  \n",
        "  # build classifier\n",
        "  (_train, _evaluate, _predict) = build_classifier_estimator(\n",
        "      num_features, num_labels, hidden_layers, 200)\n",
        "\n",
        "\n",
        "  def train(epochs=300):\n",
        "    _train(x_train, y_train, batch_size, epochs, learning_rate, 0.45, 0.01, 4)\n",
        "\n",
        "\n",
        "  def evaluate():\n",
        "    (cost_val, accuracy_val) = _evaluate(x_train, y_train, batch_size)\n",
        "    print(\"Train metric:\")\n",
        "    print({\"accuracy\": accuracy_val, \"loss\": cost_val})\n",
        "    \n",
        "    (cost_val, accuracy_val) = _evaluate(x_test, y_test, batch_size)\n",
        "    print(\"Test metric:\")\n",
        "    print({\"accuracy\": accuracy_val, \"loss\": cost_val})\n",
        "\n",
        "\n",
        "  def predict():\n",
        "    df = _predict(x_test, ds.target_names, batch_size)\n",
        "    df.index = x_test_ds.index\n",
        "    ydata = ds.target_names[np.argmax(y_test, axis=1)]\n",
        "    df[\"ydata\"] = ydata\n",
        "    df[\"max_prob\"] = df.iloc[:, 0:10].apply(lambda x: x.max(), axis=1)\n",
        "    return df\n",
        "  \n",
        "  def plot_image(df_pred):\n",
        "    idx = df_pred.index.to_numpy()\n",
        "    images_labels_pred = list(zip(ds.images[idx], ds.target[idx], df_pred[\"ypred\"].to_numpy()))\n",
        "    for index, (image, label, pred) in enumerate(images_labels_pred[:10]):\n",
        "        plt.subplot(2, 5, index + 1)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "        plt.title('Y:%i, P:%i' % (label, pred))\n",
        "\n",
        "\n",
        "  return (train, evaluate, predict, plot_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M7keRw4XYKm",
        "colab_type": "code",
        "outputId": "bda2b271-ef52-4523-daf4-62f4ed62effd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "(ex_train, ex_eval, ex_predict, plot_image) = ex()\n",
        "ex_train(1000)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0 \t| Loss = 310.58295 \t| Accuracy = 0.0625\n",
            "Iteration 200 \t| Loss = 4.690764 \t| Accuracy = 0.9921875\n",
            "Iteration 400 \t| Loss = 1.0292569 \t| Accuracy = 1.0\n",
            "Iteration 600 \t| Loss = 0.2714968 \t| Accuracy = 1.0\n",
            "Iteration 800 \t| Loss = 0.13072473 \t| Accuracy = 1.0\n",
            "Iteration 1000 \t| Loss = 0.047228623 \t| Accuracy = 1.0\n",
            "Iteration 1200 \t| Loss = 0.03467843 \t| Accuracy = 1.0\n",
            "Iteration 1400 \t| Loss = 0.02053928 \t| Accuracy = 1.0\n",
            "Iteration 1600 \t| Loss = 0.020739263 \t| Accuracy = 1.0\n",
            "Iteration 1800 \t| Loss = 0.016820185 \t| Accuracy = 1.0\n",
            "Iteration 2000 \t| Loss = 0.0059513547 \t| Accuracy = 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clG8Da9B7Cl2",
        "colab_type": "code",
        "outputId": "265d2431-12a5-4048-cae8-7cb6a4c67231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "ex_eval()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train metric:\n",
            "{'accuracy': 1.0, 'loss': 0.0011329678818583488}\n",
            "Test metric:\n",
            "{'accuracy': 0.9850446462631226, 'loss': 3.108939552307129}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK9oMygO1yqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = ex_predict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPlJRTYig97x",
        "colab_type": "code",
        "outputId": "7fa6495d-b29e-4e3d-c11d-785bf918566e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "print(\"Correct prediction:\")\n",
        "df_correct = df.loc[df[\"ypred\"] == df[\"ydata\"]]\n",
        "df_correct"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct prediction:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>ypred</th>\n",
              "      <th>ydata</th>\n",
              "      <th>max_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>635</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1448</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>921</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1477</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>926</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>534 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0    1    2    3    4    5    6    7    8    9  ypred  ydata  max_prob\n",
              "635   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0      9      9       1.0\n",
              "1448  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0      5      5       1.0\n",
              "921   0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0      6      6       1.0\n",
              "1477  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0      3      3       1.0\n",
              "459   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0      9      9       1.0\n",
              "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...       ...\n",
              "926   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0      1      1       1.0\n",
              "269   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0      3      3       1.0\n",
              "728   0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0      6      6       1.0\n",
              "410   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0      4      4       1.0\n",
              "119   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0      9      9       1.0\n",
              "\n",
              "[534 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO_2YG5RhEvr",
        "colab_type": "code",
        "outputId": "40024840-d36a-489a-d0da-869adf8f94b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "print(\"Wrong prediction:\")\n",
        "df_err = df.loc[df[\"ypred\"] != df[\"ydata\"]]\n",
        "df_err"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrong prediction:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>ypred</th>\n",
              "      <th>ydata</th>\n",
              "      <th>max_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.986</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>0.986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1149</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.987</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.000</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>0.987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>792</th>\n",
              "      <td>0.347</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.292</td>\n",
              "      <td>0.203</td>\n",
              "      <td>0.158</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0.347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.802</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.197</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.029</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.855</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.049</td>\n",
              "      <td>0.067</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>0.855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0      1      2      3      4  ...      8      9  ypred  ydata  max_prob\n",
              "480   0.001  0.000  0.000  0.000  0.000  ...  0.000  0.986      9      7     0.986\n",
              "1149  0.000  0.002  0.002  0.000  0.001  ...  0.006  0.000      7      8     0.987\n",
              "792   0.347  0.000  0.000  0.000  0.292  ...  0.000  0.000      0      6     0.347\n",
              "794   0.000  0.802  0.000  0.000  0.000  ...  0.197  0.000      1      8     0.802\n",
              "1197  0.000  0.000  0.000  0.029  0.000  ...  0.049  0.067      5      8     0.855\n",
              "5     0.000  0.000  0.000  0.000  0.000  ...  0.000  1.000      9      5     1.000\n",
              "\n",
              "[6 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSGPr4g279Hx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "df726845-92b4-4a93-aa00-2215835b4c45"
      },
      "source": [
        "plot_image(df_err)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADOCAYAAACdDdHuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F17Gvez03R1",
        "colab_type": "code",
        "outputId": "b2b9426c-3463-4a5a-b431-c8d77a944ab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "print(\"Correct prediction with high probability\")\n",
        "df_certain = df.loc[(df[\"ypred\"] == df[\"ydata\"]) & (df[\"max_prob\"] >= 0.995)]\n",
        "df_certain"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct prediction with high probability\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>ypred</th>\n",
              "      <th>ydata</th>\n",
              "      <th>max_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>635</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1448</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>921</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1477</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>926</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>514 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0    1    2    3    4    5    6    7    8    9  ypred  ydata  max_prob\n",
              "635   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0      9      9       1.0\n",
              "1448  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0      5      5       1.0\n",
              "921   0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0      6      6       1.0\n",
              "1477  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0      3      3       1.0\n",
              "459   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0      9      9       1.0\n",
              "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...       ...\n",
              "926   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0      1      1       1.0\n",
              "269   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0      3      3       1.0\n",
              "728   0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0      6      6       1.0\n",
              "410   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0      4      4       1.0\n",
              "119   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0      9      9       1.0\n",
              "\n",
              "[514 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}