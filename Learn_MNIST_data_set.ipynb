{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learn MNIST data set.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FCZBMVPPU5na"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t2wain/colab/blob/master/Learn_MNIST_data_set.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oVfh3gDPQg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCZBMVPPU5na",
        "colab_type": "text"
      },
      "source": [
        "# Inspecting data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkjcgVWmQMiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digits = datasets.load_digits()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAgiAhWIRtwy",
        "colab_type": "code",
        "outputId": "66a9c668-0106-4250-c38f-f38ecac4b8f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"data:\", digits.data.shape, type(digits.data))\n",
        "print(\"target:\", digits.target.shape, type(digits.target))\n",
        "print(\"target_names:\", digits.target_names.shape, type(digits.target_names))\n",
        "print(\"images:\", digits.images.shape, type(digits.images))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data: (1797, 64) <class 'numpy.ndarray'>\n",
            "target: (1797,) <class 'numpy.ndarray'>\n",
            "target_names: (10,) <class 'numpy.ndarray'>\n",
            "images: (1797, 8, 8) <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9BWnNASTpYh",
        "colab_type": "code",
        "outputId": "4be5fae4-d1ff-4a72-a88e-2ba3c9f4e3fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "images_and_labels = list(zip(digits.images, digits.target))\n",
        "for index, (image, label) in enumerate(images_and_labels[:10]):\n",
        "    plt.subplot(2, 5, index + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    plt.title('Training: %i' % label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADfCAYAAADWQznrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nW5IKY3BLUmEMbkkqjMEtSYX5f+JS8Lp4AVjOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y97UWz8OV3vb",
        "colab_type": "text"
      },
      "source": [
        "# Example 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii6ljKYDV65D",
        "colab_type": "text"
      },
      "source": [
        "## Utility methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Zm1II56Y3Dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_gen(X, Y=None, batch_size=1, epochs=1):\n",
        "  X_size, _ = X.shape\n",
        "\n",
        "  for ep in range(epochs):\n",
        "    for step in range(X_size // batch_size):\n",
        "      offset = (step * batch_size) % X_size\n",
        "      batch_x = X[offset:(offset + batch_size), :]\n",
        "      batch_y = None if Y is None else Y[offset:(offset + batch_size)]\n",
        "      yield (batch_x, batch_y)\n",
        "    remainder = X_size % batch_size\n",
        "    if remainder > 0:\n",
        "      offset = X_size - remainder\n",
        "      batch_x = X[offset:, :]\n",
        "      batch_y = None if Y is None else Y[offset:]\n",
        "      yield (batch_x, batch_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU4m55J7ln6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_dnn(num_features, num_labels, hiddens=[]):\n",
        "  \n",
        "  def loss(Y, y_prob):\n",
        "    xentropy = -tf.reduce_sum(Y * tf.log(y_prob), reduction_indices=1)\n",
        "    loss = tf.reduce_mean(xentropy, name='cost')\n",
        "    return loss\n",
        "\n",
        "\n",
        "  def loss_logit(Y, logit):\n",
        "    xentropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=Y)\n",
        "    loss = tf.reduce_mean(tf.reduce_sum(xentropy), name='cost')\n",
        "    #loss = tf.reduce_sum(xentropy, name='cost')\n",
        "    return loss\n",
        "\n",
        "\n",
        "  num_sample = None\n",
        "  with tf.name_scope('placeholders'):\n",
        "    Xin = tf.placeholder(tf.float32, shape=[num_sample, num_features], name='Xin')\n",
        "    Yin = tf.placeholder(tf.float32, shape=[num_sample, num_labels], name='Yin')\n",
        "    rate = tf.placeholder(tf.float32, name='dropout_rate')\n",
        "  \n",
        "  X = Xin; W = None; layers = []; y_out = None\n",
        "  # create nodes for hidden layers\n",
        "  num_input = num_features\n",
        "  num_hidden_layers = len(hiddens)\n",
        "\n",
        "  for layer_num, num_node_output in enumerate(hiddens):\n",
        "    layer_name = \"hidden_layer_%d\" % (layer_num+1)\n",
        "    with tf.name_scope(layer_name):\n",
        "      with tf.variable_scope(layer_name):\n",
        "        W = tf.get_variable('W', \n",
        "          initializer=tf.truncated_normal([num_input, num_node_output], stddev=0.1))\n",
        "        b = tf.get_variable('b', \n",
        "          initializer=tf.Variable(tf.constant(0.1,shape=[num_node_output])))\n",
        "      fx = tf.add(tf.matmul(X, W), b) # linear regression\n",
        "      y_out = tf.nn.relu6(fx) # activation funtion to introduce non-linearity\n",
        "      # apply dropout to hidden layer to introduce regularization of W\n",
        "      layer_drop = tf.nn.dropout(y_out, rate=rate, name='y_out')\n",
        "      y_out = layer_drop\n",
        "      # keeping track of each layer\n",
        "      layers.append({\"W\": W, \"b\": b, \"out\": y_out, \"W_val\": None, \"b_val\": None})\n",
        "      X = y_out # y become Xin to next layer\n",
        "      num_input = num_node_output\n",
        "  \n",
        "  # create output layer\n",
        "  num_input = num_features if W is None else num_input\n",
        "  num_node_output = num_labels\n",
        "  with tf.name_scope('output'):\n",
        "    with tf.variable_scope('output'):\n",
        "      W = tf.get_variable('W', \n",
        "        initializer=tf.truncated_normal([num_input, num_node_output], stddev=0.1))\n",
        "      b = tf.get_variable('b', \n",
        "        initializer=tf.constant(0.1,shape=[num_node_output]))\n",
        "    y_logit = tf.add(tf.matmul(X, W), b) # logistic regression, ln-odd\n",
        "    # convert to probability, exp-logit, and normalize to interval between 0 and 1\n",
        "    y_prob = tf.nn.softmax(y_logit, name='y_prob')\n",
        "    layers.append({\"W\": W, \"b\": b, \"out\": y_prob, \"W_val\": None, \"b_val\": None})\n",
        "    y_pred = tf.argmax(y_prob, 1, name='y_pred') # index of max probablity\n",
        "    y_label = tf.argmax(Yin, 1, name='y_label') # index of one-hot label\n",
        "\n",
        "  with tf.name_scope('optimize'):\n",
        "    cost = loss_logit(Yin, y_logit)\n",
        "    #cost = loss(Yin, y_prob)\n",
        "    op = tf.train.AdamOptimizer()\n",
        "    # minimize cost/loss\n",
        "    train_op = op.minimize(cost)\n",
        "  \n",
        "  with tf.name_scope('metrics'):\n",
        "    correct_prediction = tf.equal(y_pred, y_label)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"), name='accuracy')\n",
        "  \n",
        "  return {\"x\": Xin, \"y\": Yin, \"dropout_rate\": rate, \"layers\": layers, \n",
        "          \"cost\": cost, \"accuracy\": accuracy, \"y_prob\": y_prob, \"y_pred\": y_pred,\n",
        "          \"op\": op, \"train_op\": train_op}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E-Zi4LkjF_Gs",
        "colab": {}
      },
      "source": [
        "def build_classifier_estimator(num_features, num_labels, hiddens=[], msg_per_steps=0):\n",
        "  is_saved = False\n",
        "  \n",
        "  g1 = tf.Graph()\n",
        "  with g1.as_default() as graph:\n",
        "    dnn = build_dnn(num_features, num_labels, hiddens)\n",
        "\n",
        "  # placeholders, input to the training\n",
        "  X = dnn[\"x\"]\n",
        "  Y = dnn[\"y\"]\n",
        "  rate = dnn[\"dropout_rate\"]\n",
        "\n",
        "  # optimizer\n",
        "  op = dnn[\"op\"]\n",
        "  train_op = dnn[\"train_op\"]\n",
        "\n",
        "  # metrics\n",
        "  cost = dnn[\"cost\"]\n",
        "  accuracy = dnn[\"accuracy\"]\n",
        "  y_pred = dnn[\"y_pred\"]\n",
        "  y_prob = dnn[\"y_prob\"]\n",
        "  \n",
        "\n",
        "  def train(xsample, ysample,  batch_size=1, training_epochs=1, \n",
        "            learning_rate=0.001, dropout_rate=0, max_loss=0.01, limit_count=4):\n",
        "    op.learning_rate = learning_rate\n",
        "    loss_count = 0\n",
        "    with tf.Session(graph=g1) as sess:\n",
        "      _restoreVars(sess)\n",
        "      step_iterator = enumerate(data_gen(xsample, ysample,  batch_size, training_epochs))\n",
        "      for step, (batch_xs, batch_labels) in step_iterator:\n",
        "        feed_dict = {X: batch_xs, Y: batch_labels, rate: dropout_rate}\n",
        "        sess.run(train_op, feed_dict=feed_dict)\n",
        "\n",
        "        # print training progress\n",
        "        if msg_per_steps > 0 and step % msg_per_steps == 0:\n",
        "          feed_dict = {X: batch_xs, Y: batch_labels, rate: 0}\n",
        "          cost_val, accuracy_val = sess.run([cost, accuracy], feed_dict=feed_dict)\n",
        "          print(\n",
        "              \"Iteration\", str(step), \n",
        "              \"\\t| Loss =\", str(cost_val), \n",
        "              \"\\t| Accuracy =\", str(accuracy_val))\n",
        "          \n",
        "        # early training stop\n",
        "        if math.isnan(cost_val) or loss_count > limit_count:\n",
        "          break;\n",
        "        elif cost_val < max_loss:\n",
        "          loss_count += 1\n",
        "          \n",
        "      _saveVars(sess)\n",
        "\n",
        "      \n",
        "  def _restoreVars(sess):\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    if is_saved:\n",
        "      for layer in dnn[\"layers\"]:\n",
        "        sess.run(layer[\"W\"].assign(layer[\"W_val\"]))\n",
        "        sess.run(layer[\"b\"].assign(layer[\"b_val\"]))\n",
        "\n",
        "    \n",
        "  def _saveVars(sess):\n",
        "    nonlocal is_saved\n",
        "    is_saved = True\n",
        "    for layer in dnn[\"layers\"]:\n",
        "      layer[\"W_val\"] = sess.run(layer[\"W\"])\n",
        "      layer[\"b_val\"] = sess.run(layer[\"b\"])\n",
        "\n",
        "      \n",
        "  def evaluate(xsample, ysample, batch_size=1):\n",
        "    if not is_saved:\n",
        "      return \"Error: Training has not been done.\"\n",
        "\n",
        "    with tf.Session(graph=g1) as sess:\n",
        "      _restoreVars(sess)\n",
        "      cost_total = accuracy_total = step = 0\n",
        "      for step, (batch_xs, batch_ys) in enumerate(data_gen(xsample, ysample,  batch_size)):\n",
        "        feed_dict = {X: batch_xs, Y: batch_ys, rate: 0}\n",
        "        cost_val, accuracy_val = sess.run([cost, accuracy], feed_dict=feed_dict)\n",
        "        cost_total += cost_val\n",
        "        accuracy_total += accuracy_val\n",
        "      return (cost_val/(step+1), accuracy_total/(step+1))\n",
        "\n",
        "    \n",
        "  def predict(xdata, labels, batch_size=1):\n",
        "    if not is_saved:\n",
        "      return \"Error: Training has not been done.\"\n",
        "      \n",
        "    with tf.Session(graph=g1) as sess:\n",
        "      _restoreVars(sess)\n",
        "      pred = []; prob = []\n",
        "      for (batch_xs, _) in data_gen(xdata, batch_size=batch_size):\n",
        "        feed_dict={X: batch_xs, rate: 0}\n",
        "        yprob = sess.run(y_prob, feed_dict=feed_dict)\n",
        "        ypred = np.argmax(yprob, axis=1)\n",
        "        pred.extend(ypred)\n",
        "        prob.extend(yprob.round(3))\n",
        "        \n",
        "      df = pd.DataFrame(prob, columns=labels)\n",
        "      plabel = labels[pred]\n",
        "      df[\"ypred\"] = plabel\n",
        "      return df\n",
        "\n",
        "    \n",
        "  return (train, evaluate, predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAS37b0NfoIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot(labels, ydata):\n",
        "  y_target = np.expand_dims(ydata, axis=1)\n",
        "  enc = OneHotEncoder(categories=[labels])\n",
        "  enc.fit(y_target)\n",
        "  return (labels, enc.transform(y_target).toarray())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdTWTZuAWbAP",
        "colab_type": "text"
      },
      "source": [
        "## Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWHbAea6ns4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tensors_ex():\n",
        "  g1 = tf.Graph()\n",
        "  with g1.as_default() as graph:\n",
        "    dnn = build_dnn(3, 4, [2,2])\n",
        "    t = {\"x\": graph.get_tensor_by_name('placeholders/Xin:0'), \n",
        "        \"y\": graph.get_tensor_by_name('placeholders/Yin:0'), \n",
        "        \"dropout_rate\": graph.get_tensor_by_name('placeholders/dropout_rate:0'), \n",
        "        \"cost\": graph.get_tensor_by_name('optimize/cost:0'), \n",
        "        \"accuracy\": graph.get_tensor_by_name('metrics/accuracy:0'), \n",
        "        \"out\": graph.get_tensor_by_name('output/y_pred:0')}\n",
        "  return (dnn, t)\n",
        "\n",
        "\n",
        "get_tensors_ex()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaDLw1PCwJj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(nsample=None):\n",
        "  ds = datasets.load_digits()\n",
        "  \n",
        "  # build dataframe\n",
        "  df = pd.DataFrame(ds.data)\n",
        "  df[\"ydata\"] = ds.target\n",
        "  \n",
        "  # get subset of data\n",
        "  if not nsample==None:\n",
        "    df = df.sample(nsample)\n",
        "    \n",
        "  # normalization\n",
        "  df.iloc[:,:-1] = df.iloc[:,:-1].apply((lambda x: (x - x.mean()) / x.std()), axis=1)\n",
        "  \n",
        "  # one-hot encoding the target\n",
        "  y_labels, y_dummies = one_hot(ds.target_names, df[\"ydata\"].to_numpy())\n",
        "  dhot = pd.DataFrame(y_dummies, columns=y_labels)\n",
        "    \n",
        "  # split dataset into train and test\n",
        "  x_train, x_test, y_train, y_test = train_test_split(\n",
        "    df, dhot, test_size=0.3)\n",
        "\n",
        "  return (x_train, x_test, y_train, y_test, ds)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvbFTWk3WdHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ex(nsample=None):\n",
        "  batch_size = 128\n",
        "  learning_rate = 0.0001\n",
        "  hidden_layers = [256,256]\n",
        "  \n",
        "  (x_train_ds, x_test_ds, y_train_ds, y_test_ds, ds) = get_data(nsample)\n",
        "  x_train = x_train_ds.iloc[:,:-1].to_numpy()\n",
        "  x_test = x_test_ds.iloc[:,:-1].to_numpy()\n",
        "  y_train = y_train_ds.to_numpy()\n",
        "  y_test = y_test_ds.to_numpy()\n",
        "\n",
        "  train_size, num_features = x_train.shape\n",
        "  num_labels = ds.target_names.shape[0]\n",
        "  \n",
        "  # build classifier\n",
        "  (_train, _evaluate, _predict) = build_classifier_estimator(\n",
        "      num_features, num_labels, hidden_layers, 200)\n",
        "\n",
        "\n",
        "  def train(epochs=300, max_loss=0.01):\n",
        "    _train(x_train, y_train, batch_size, epochs, learning_rate, 0.45, max_loss, 4)\n",
        "\n",
        "\n",
        "  def evaluate():\n",
        "    (cost_val, accuracy_val) = _evaluate(x_train, y_train, batch_size)\n",
        "    print(\"Train metric:\")\n",
        "    print({\"accuracy\": accuracy_val, \"loss\": cost_val})\n",
        "    \n",
        "    (cost_val, accuracy_val) = _evaluate(x_test, y_test, batch_size)\n",
        "    print(\"Test metric:\")\n",
        "    print({\"accuracy\": accuracy_val, \"loss\": cost_val})\n",
        "\n",
        "\n",
        "  def predict():\n",
        "    df = _predict(x_test, ds.target_names, batch_size)\n",
        "    df.index = x_test_ds.index\n",
        "    ydata = ds.target_names[np.argmax(y_test, axis=1)]\n",
        "    df[\"ydata\"] = ydata\n",
        "    df[\"max_prob\"] = df.iloc[:, 0:10].apply(lambda x: x.max(), axis=1)\n",
        "    return df\n",
        "  \n",
        "  def plot_image(df_pred, title):\n",
        "    idx = df_pred.index.to_numpy()\n",
        "    images_labels_pred = list(zip(ds.images[idx], ds.target[idx], df_pred[\"ypred\"].to_numpy()))\n",
        "    fig = plt.figure()\n",
        "    fig.suptitle(title, fontsize=16)\n",
        "    for index, (image, label, pred) in enumerate(images_labels_pred[:10]):\n",
        "        plt.subplot(2, 5, index + 1)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "        plt.title('P:%i, D:%i' % (pred, label))\n",
        "\n",
        "\n",
        "  return (train, evaluate, predict, plot_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M7keRw4XYKm",
        "colab_type": "code",
        "outputId": "3323d4ad-bc66-460c-a19f-0fff4a9f121c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "(ex_train, ex_eval, ex_predict, plot_image) = ex()\n",
        "ex_train(1000, 1)"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0 \t| Loss = 278.48907 \t| Accuracy = 0.21875\n",
            "Iteration 200 \t| Loss = 2.7276168 \t| Accuracy = 1.0\n",
            "Iteration 400 \t| Loss = 0.8179802 \t| Accuracy = 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clG8Da9B7Cl2",
        "colab_type": "code",
        "outputId": "0f305bb3-f038-4d9f-d2a4-1fbcb436a115",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "ex_eval()"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train metric:\n",
            "{'accuracy': 0.99921875, 'loss': 0.0385860949754715}\n",
            "Test metric:\n",
            "{'accuracy': 0.9850446462631226, 'loss': 0.7067295551300049}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK9oMygO1yqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = ex_predict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPlJRTYig97x",
        "colab_type": "code",
        "outputId": "fce627ca-179b-4c03-bd34-f15bcabcbf8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "print(\"Correct prediction:\")\n",
        "df_correct = df.loc[df[\"ypred\"] == df[\"ydata\"]].sort_values([\"max_prob\"], axis=0, ascending=True)\n",
        "df_correct"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct prediction:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>ypred</th>\n",
              "      <th>ydata</th>\n",
              "      <th>max_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.066</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.038</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.314</td>\n",
              "      <td>0.215</td>\n",
              "      <td>0.361</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>0.361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>0.488</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.036</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.521</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.376</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1603</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.643</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.022</td>\n",
              "      <td>0.329</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>580</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1156</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1129</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>534 rows Ã— 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0      1      2      3      4  ...      8      9  ypred  ydata  max_prob\n",
              "69    0.0  0.066  0.002  0.000  0.038  ...  0.215  0.361      9      9     0.361\n",
              "77    0.0  0.469  0.488  0.000  0.001  ...  0.005  0.000      2      2     0.488\n",
              "449   0.0  0.000  0.001  0.521  0.000  ...  0.000  0.376      3      3     0.521\n",
              "1603  0.0  0.000  0.001  0.577  0.000  ...  0.000  0.001      3      3     0.577\n",
              "446   0.0  0.000  0.002  0.643  0.000  ...  0.022  0.329      3      3     0.643\n",
              "...   ...    ...    ...    ...    ...  ...    ...    ...    ...    ...       ...\n",
              "266   1.0  0.000  0.000  0.000  0.000  ...  0.000  0.000      0      0     1.000\n",
              "580   0.0  0.000  0.000  0.000  1.000  ...  0.000  0.000      4      4     1.000\n",
              "1156  0.0  0.000  0.000  0.000  0.000  ...  1.000  0.000      8      8     1.000\n",
              "1129  0.0  0.000  0.000  0.000  0.000  ...  0.000  0.000      5      5     1.000\n",
              "531   0.0  0.000  0.000  0.000  0.000  ...  0.000  0.000      5      5     1.000\n",
              "\n",
              "[534 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11-Vb0mGR6Ss",
        "colab_type": "code",
        "outputId": "251e6933-e0c3-4f79-a680-505f1b15f52d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "ax = sns.distplot(df_correct[\"max_prob\"], kde=False, rug=True, bins=10)\n",
        "ax.set_title(\"Correct Prediction Probability\")\n",
        "ax.set_ylabel(\"Image Count\")\n",
        "ax.set_xlabel(\"Prediction Probability\")\n",
        "plt.show()"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nScHMzHJOCmZmlnNSMDOz3P8CWFgolboymicAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO_2YG5RhEvr",
        "colab_type": "code",
        "outputId": "2bce9372-7305-4d22-cbd1-6d3fbbdbdab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "print(\"Wrong prediction:\")\n",
        "df_err = df.loc[df[\"ypred\"] != df[\"ydata\"]].sort_values([\"max_prob\"], axis=0, ascending=False)\n",
        "df_err"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrong prediction:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>ypred</th>\n",
              "      <th>ydata</th>\n",
              "      <th>max_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.997</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.988</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1551</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.983</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.014</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0.983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1729</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.084</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.829</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.059</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0.829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>784</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.058</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.763</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>0.763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1628</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.434</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.404</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.106</td>\n",
              "      <td>0.052</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.434</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0      1     2      3      4  ...      8      9  ypred  ydata  max_prob\n",
              "5     0.000  0.002  0.00  0.001  0.000  ...  0.000  0.997      9      5     0.997\n",
              "905   0.000  0.988  0.00  0.000  0.002  ...  0.002  0.000      1      8     0.988\n",
              "1551  0.000  0.983  0.00  0.000  0.001  ...  0.001  0.000      1      6     0.983\n",
              "1729  0.001  0.013  0.00  0.084  0.000  ...  0.000  0.059      5      3     0.829\n",
              "784   0.000  0.058  0.01  0.005  0.001  ...  0.137  0.000      6      8     0.763\n",
              "1628  0.000  0.434  0.00  0.000  0.404  ...  0.106  0.052      1      4     0.434\n",
              "\n",
              "[6 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSGPr4g279Hx",
        "colab_type": "code",
        "outputId": "97682589-e59c-4a9b-f251-b83cce0a93bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "plot_image(df_err, \"Wrong Prediction\")"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADwCAYAAACjfbczAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F17Gvez03R1",
        "colab_type": "code",
        "outputId": "00bdfc96-1646-4b6c-836d-dc90ec1590ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "prob_threshold = 0.995\n",
        "print(\"Correct prediction with high probability\")\n",
        "df_correct.loc[df[\"max_prob\"] >= prob_threshold]"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct prediction with high probability\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>ypred</th>\n",
              "      <th>ydata</th>\n",
              "      <th>max_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.995</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.000</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1645</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.995</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.000</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>947</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.995</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1152</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.995</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>0.995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.995</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>0.995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>580</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1156</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1129</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>451 rows Ã— 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0      1      2      3      4  ...      8      9  ypred  ydata  max_prob\n",
              "402   0.001  0.000  0.000  0.000  0.001  ...  0.002  0.000      6      6     0.995\n",
              "1645  0.000  0.003  0.000  0.000  0.000  ...  0.002  0.000      6      6     0.995\n",
              "947   0.000  0.995  0.002  0.002  0.000  ...  0.000  0.000      1      1     0.995\n",
              "1152  0.000  0.003  0.000  0.001  0.000  ...  0.001  0.995      9      9     0.995\n",
              "459   0.001  0.000  0.000  0.002  0.000  ...  0.000  0.995      9      9     0.995\n",
              "...     ...    ...    ...    ...    ...  ...    ...    ...    ...    ...       ...\n",
              "266   1.000  0.000  0.000  0.000  0.000  ...  0.000  0.000      0      0     1.000\n",
              "580   0.000  0.000  0.000  0.000  1.000  ...  0.000  0.000      4      4     1.000\n",
              "1156  0.000  0.000  0.000  0.000  0.000  ...  1.000  0.000      8      8     1.000\n",
              "1129  0.000  0.000  0.000  0.000  0.000  ...  0.000  0.000      5      5     1.000\n",
              "531   0.000  0.000  0.000  0.000  0.000  ...  0.000  0.000      5      5     1.000\n",
              "\n",
              "[451 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecrC9vsCEtgU",
        "colab_type": "code",
        "outputId": "59454381-dd1a-4eed-c2cd-604a73f03efb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "print(\"Wrong prediction despite high probability\")\n",
        "df_err.loc[df[\"max_prob\"] >= prob_threshold]"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrong prediction despite high probability\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>ypred</th>\n",
              "      <th>ydata</th>\n",
              "      <th>max_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.997</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0      1    2      3    4    5  ...    7    8      9  ypred  ydata  max_prob\n",
              "5  0.0  0.002  0.0  0.001  0.0  0.0  ...  0.0  0.0  0.997      9      5     0.997\n",
              "\n",
              "[1 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    }
  ]
}