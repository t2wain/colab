{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learn MNIST data set.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FCZBMVPPU5na"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t2wain/colab/blob/master/Learn_MNIST_data_set.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oVfh3gDPQg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCZBMVPPU5na",
        "colab_type": "text"
      },
      "source": [
        "# Inspecting data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkjcgVWmQMiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digits = datasets.load_digits()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAgiAhWIRtwy",
        "colab_type": "code",
        "outputId": "66a9c668-0106-4250-c38f-f38ecac4b8f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"data:\", digits.data.shape, type(digits.data))\n",
        "print(\"target:\", digits.target.shape, type(digits.target))\n",
        "print(\"target_names:\", digits.target_names.shape, type(digits.target_names))\n",
        "print(\"images:\", digits.images.shape, type(digits.images))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data: (1797, 64) <class 'numpy.ndarray'>\n",
            "target: (1797,) <class 'numpy.ndarray'>\n",
            "target_names: (10,) <class 'numpy.ndarray'>\n",
            "images: (1797, 8, 8) <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9BWnNASTpYh",
        "colab_type": "code",
        "outputId": "4be5fae4-d1ff-4a72-a88e-2ba3c9f4e3fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "images_and_labels = list(zip(digits.images, digits.target))\n",
        "for index, (image, label) in enumerate(images_and_labels[:10]):\n",
        "    plt.subplot(2, 5, index + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    plt.title('Training: %i' % label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADfCAYAAADWQznrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nW5IKY3BLUmEMbkkqjMEtSYX5f+JS8Lp4AVjOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y97UWz8OV3vb",
        "colab_type": "text"
      },
      "source": [
        "# Example 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii6ljKYDV65D",
        "colab_type": "text"
      },
      "source": [
        "## Utility methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Zm1II56Y3Dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_gen(X, Y=None, batch_size=1, epochs=1):\n",
        "  X_size, _ = X.shape\n",
        "\n",
        "  for ep in range(epochs):\n",
        "    for step in range(X_size // batch_size):\n",
        "      offset = (step * batch_size) % X_size\n",
        "      batch_x = X[offset:(offset + batch_size), :]\n",
        "      batch_y = None if Y is None else Y[offset:(offset + batch_size)]\n",
        "      yield (batch_x, batch_y)\n",
        "    remainder = X_size % batch_size\n",
        "    if remainder > 0:\n",
        "      offset = X_size - remainder\n",
        "      batch_x = X[offset:, :]\n",
        "      batch_y = None if Y is None else Y[offset:]\n",
        "      yield (batch_x, batch_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU4m55J7ln6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_dnn(num_features, num_labels, hiddens=[]):\n",
        "  \n",
        "  def loss(Y, y_prob):\n",
        "    xentropy = -tf.reduce_sum(Y * tf.log(y_prob), reduction_indices=1)\n",
        "    loss = tf.reduce_mean(xentropy, name='cost')\n",
        "    return loss\n",
        "\n",
        "\n",
        "  def loss_logit(Y, logit):\n",
        "    xentropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=Y)\n",
        "    loss = tf.reduce_mean(tf.reduce_sum(xentropy), name='cost')\n",
        "    #loss = tf.reduce_sum(xentropy, name='cost')\n",
        "    return loss\n",
        "\n",
        "\n",
        "  num_sample = None\n",
        "  with tf.name_scope('placeholders'):\n",
        "    Xin = tf.placeholder(tf.float32, shape=[num_sample, num_features], name='Xin')\n",
        "    Yin = tf.placeholder(tf.float32, shape=[num_sample, num_labels], name='Yin')\n",
        "    rate = tf.placeholder(tf.float32, name='dropout_rate')\n",
        "  \n",
        "  X = Xin; W = None; layers = []; y_out = None\n",
        "  # create nodes for hidden layers\n",
        "  num_input = num_features\n",
        "  num_hidden_layers = len(hiddens)\n",
        "\n",
        "  for layer_num, num_node_output in enumerate(hiddens):\n",
        "    layer_name = \"hidden_layer_%d\" % (layer_num+1)\n",
        "    with tf.name_scope(layer_name):\n",
        "      with tf.variable_scope(layer_name):\n",
        "        W = tf.get_variable('W', \n",
        "          initializer=tf.truncated_normal([num_input, num_node_output], stddev=0.1))\n",
        "        b = tf.get_variable('b', \n",
        "          initializer=tf.Variable(tf.constant(0.1,shape=[num_node_output])))\n",
        "      fx = tf.add(tf.matmul(X, W), b) # linear regression\n",
        "      y_out = tf.nn.relu6(fx) # activation funtion to introduce non-linearity\n",
        "      # apply dropout to hidden layer to introduce regularization of W\n",
        "      layer_drop = tf.nn.dropout(y_out, rate=rate, name='y_out')\n",
        "      y_out = layer_drop\n",
        "      # keeping track of each layer\n",
        "      layers.append({\"W\": W, \"b\": b, \"out\": y_out, \"W_val\": None, \"b_val\": None})\n",
        "      X = y_out # y become Xin to next layer\n",
        "      num_input = num_node_output\n",
        "  \n",
        "  # create output layer\n",
        "  num_input = num_features if W is None else num_input\n",
        "  num_node_output = num_labels\n",
        "  with tf.name_scope('output'):\n",
        "    with tf.variable_scope('output'):\n",
        "      W = tf.get_variable('W', \n",
        "        initializer=tf.truncated_normal([num_input, num_node_output], stddev=0.1))\n",
        "      b = tf.get_variable('b', \n",
        "        initializer=tf.constant(0.1,shape=[num_node_output]))\n",
        "    y_logit = tf.add(tf.matmul(X, W), b) # logistic regression, ln-odd\n",
        "    # convert to probability, exp-logit, and normalize to interval between 0 and 1\n",
        "    y_prob = tf.nn.softmax(y_logit, name='y_prob')\n",
        "    layers.append({\"W\": W, \"b\": b, \"out\": y_prob, \"W_val\": None, \"b_val\": None})\n",
        "    y_pred = tf.argmax(y_prob, 1, name='y_pred') # index of max probablity\n",
        "    y_label = tf.argmax(Yin, 1, name='y_label') # index of one-hot label\n",
        "\n",
        "  with tf.name_scope('optimize'):\n",
        "    cost = loss_logit(Yin, y_logit)\n",
        "    #cost = loss(Yin, y_prob)\n",
        "    op = tf.train.AdamOptimizer()\n",
        "    # minimize cost/loss\n",
        "    train_op = op.minimize(cost)\n",
        "  \n",
        "  with tf.name_scope('metrics'):\n",
        "    correct_prediction = tf.equal(y_pred, y_label)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"), name='accuracy')\n",
        "  \n",
        "  return {\"x\": Xin, \"y\": Yin, \"dropout_rate\": rate, \"layers\": layers, \n",
        "          \"cost\": cost, \"accuracy\": accuracy, \"y_prob\": y_prob, \"y_pred\": y_pred,\n",
        "          \"op\": op, \"train_op\": train_op}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E-Zi4LkjF_Gs",
        "colab": {}
      },
      "source": [
        "def build_classifier_estimator(num_features, num_labels, hiddens=[], msg_per_steps=0):\n",
        "  is_saved = False\n",
        "  \n",
        "  g1 = tf.Graph()\n",
        "  with g1.as_default() as graph:\n",
        "    dnn = build_dnn(num_features, num_labels, hiddens)\n",
        "\n",
        "  # placeholders, input to the training\n",
        "  X = dnn[\"x\"]\n",
        "  Y = dnn[\"y\"]\n",
        "  rate = dnn[\"dropout_rate\"]\n",
        "\n",
        "  # optimizer\n",
        "  op = dnn[\"op\"]\n",
        "  train_op = dnn[\"train_op\"]\n",
        "\n",
        "  # metrics\n",
        "  cost = dnn[\"cost\"]\n",
        "  accuracy = dnn[\"accuracy\"]\n",
        "  y_pred = dnn[\"y_pred\"]\n",
        "  y_prob = dnn[\"y_prob\"]\n",
        "  \n",
        "\n",
        "  def train(xsample, ysample,  batch_size=1, training_epochs=1, \n",
        "            learning_rate=0.001, dropout_rate=0, max_loss=0.01, limit_count=4):\n",
        "    op.learning_rate = learning_rate\n",
        "    loss_count = 0\n",
        "    with tf.Session(graph=g1) as sess:\n",
        "      _restoreVars(sess)\n",
        "      step_iterator = enumerate(data_gen(xsample, ysample,  batch_size, training_epochs))\n",
        "      for step, (batch_xs, batch_labels) in step_iterator:\n",
        "        feed_dict = {X: batch_xs, Y: batch_labels, rate: dropout_rate}\n",
        "        sess.run(train_op, feed_dict=feed_dict)\n",
        "\n",
        "        # print training progress\n",
        "        if msg_per_steps > 0 and step % msg_per_steps == 0:\n",
        "          feed_dict = {X: batch_xs, Y: batch_labels, rate: 0}\n",
        "          cost_val, accuracy_val = sess.run([cost, accuracy], feed_dict=feed_dict)\n",
        "          print(\n",
        "              \"Iteration\", str(step), \n",
        "              \"\\t| Loss =\", str(cost_val), \n",
        "              \"\\t| Accuracy =\", str(accuracy_val))\n",
        "          \n",
        "        # early training stop\n",
        "        if math.isnan(cost_val) or loss_count > limit_count:\n",
        "          break;\n",
        "        elif cost_val < max_loss:\n",
        "          loss_count += 1\n",
        "          \n",
        "      _saveVars(sess)\n",
        "\n",
        "      \n",
        "  def _restoreVars(sess):\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    if is_saved:\n",
        "      for layer in dnn[\"layers\"]:\n",
        "        sess.run(layer[\"W\"].assign(layer[\"W_val\"]))\n",
        "        sess.run(layer[\"b\"].assign(layer[\"b_val\"]))\n",
        "\n",
        "    \n",
        "  def _saveVars(sess):\n",
        "    nonlocal is_saved\n",
        "    is_saved = True\n",
        "    for layer in dnn[\"layers\"]:\n",
        "      layer[\"W_val\"] = sess.run(layer[\"W\"])\n",
        "      layer[\"b_val\"] = sess.run(layer[\"b\"])\n",
        "\n",
        "      \n",
        "  def evaluate(xsample, ysample, batch_size=1):\n",
        "    if not is_saved:\n",
        "      return \"Error: Training has not been done.\"\n",
        "\n",
        "    with tf.Session(graph=g1) as sess:\n",
        "      _restoreVars(sess)\n",
        "      cost_total = accuracy_total = step = 0\n",
        "      for step, (batch_xs, batch_ys) in enumerate(data_gen(xsample, ysample,  batch_size)):\n",
        "        feed_dict = {X: batch_xs, Y: batch_ys, rate: 0}\n",
        "        cost_val, accuracy_val = sess.run([cost, accuracy], feed_dict=feed_dict)\n",
        "        cost_total += cost_val\n",
        "        accuracy_total += accuracy_val\n",
        "      return (cost_val/(step+1), accuracy_total/(step+1))\n",
        "\n",
        "    \n",
        "  def predict(xdata, labels, batch_size=1):\n",
        "    if not is_saved:\n",
        "      return \"Error: Training has not been done.\"\n",
        "      \n",
        "    with tf.Session(graph=g1) as sess:\n",
        "      _restoreVars(sess)\n",
        "      pred = []; prob = []\n",
        "      for (batch_xs, _) in data_gen(xdata, batch_size=batch_size):\n",
        "        feed_dict={X: batch_xs, rate: 0}\n",
        "        yprob = sess.run(y_prob, feed_dict=feed_dict)\n",
        "        ypred = np.argmax(yprob, axis=1)\n",
        "        pred.extend(ypred)\n",
        "        prob.extend(yprob.round(3))\n",
        "        \n",
        "      df = pd.DataFrame(prob, columns=labels)\n",
        "      plabel = labels[pred]\n",
        "      df[\"ypred\"] = plabel\n",
        "      return df\n",
        "\n",
        "    \n",
        "  return (train, evaluate, predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAS37b0NfoIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot(labels, ydata):\n",
        "  y_target = np.expand_dims(ydata, axis=1)\n",
        "  enc = OneHotEncoder(categories=[labels])\n",
        "  enc.fit(y_target)\n",
        "  return (labels, enc.transform(y_target).toarray())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdTWTZuAWbAP",
        "colab_type": "text"
      },
      "source": [
        "## Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWHbAea6ns4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tensors_ex():\n",
        "  g1 = tf.Graph()\n",
        "  with g1.as_default() as graph:\n",
        "    dnn = build_dnn(3, 4, [2,2])\n",
        "    t = {\"x\": graph.get_tensor_by_name('placeholders/Xin:0'), \n",
        "        \"y\": graph.get_tensor_by_name('placeholders/Yin:0'), \n",
        "        \"dropout_rate\": graph.get_tensor_by_name('placeholders/dropout_rate:0'), \n",
        "        \"cost\": graph.get_tensor_by_name('optimize/cost:0'), \n",
        "        \"accuracy\": graph.get_tensor_by_name('metrics/accuracy:0'), \n",
        "        \"out\": graph.get_tensor_by_name('output/y_pred:0')}\n",
        "  return (dnn, t)\n",
        "\n",
        "\n",
        "get_tensors_ex()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaDLw1PCwJj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(nsample=None):\n",
        "  ds = datasets.load_digits()\n",
        "  \n",
        "  # build dataframe\n",
        "  df = pd.DataFrame(ds.data)\n",
        "  df[\"ydata\"] = ds.target\n",
        "  \n",
        "  # get subset of data\n",
        "  if not nsample==None:\n",
        "    df = df.sample(nsample)\n",
        "    \n",
        "  # normalization\n",
        "  df.iloc[:,:-1] = df.iloc[:,:-1].apply((lambda x: (x - x.mean()) / x.std()), axis=1)\n",
        "  \n",
        "  # one-hot encoding the target\n",
        "  y_labels, y_dummies = one_hot(ds.target_names, df[\"ydata\"].to_numpy())\n",
        "  dhot = pd.DataFrame(y_dummies, columns=y_labels)\n",
        "    \n",
        "  # split dataset into train and test\n",
        "  x_train, x_test, y_train, y_test = train_test_split(\n",
        "    df, dhot, test_size=0.3)\n",
        "\n",
        "  return (x_train, x_test, y_train, y_test, ds)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvbFTWk3WdHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ex(nsample=None):\n",
        "  batch_size = 128\n",
        "  learning_rate = 0.0001\n",
        "  hidden_layers = [256,256]\n",
        "  \n",
        "  (x_train_ds, x_test_ds, y_train_ds, y_test_ds, ds) = get_data(nsample)\n",
        "  x_train = x_train_ds.iloc[:,:-1].to_numpy()\n",
        "  x_test = x_test_ds.iloc[:,:-1].to_numpy()\n",
        "  y_train = y_train_ds.to_numpy()\n",
        "  y_test = y_test_ds.to_numpy()\n",
        "\n",
        "  train_size, num_features = x_train.shape\n",
        "  num_labels = ds.target_names.shape[0]\n",
        "  \n",
        "  # build classifier\n",
        "  (_train, _evaluate, _predict) = build_classifier_estimator(\n",
        "      num_features, num_labels, hidden_layers, 200)\n",
        "\n",
        "\n",
        "  def train(epochs=300):\n",
        "    _train(x_train, y_train, batch_size, epochs, learning_rate, 0.45, 0.01, 4)\n",
        "\n",
        "\n",
        "  def evaluate():\n",
        "    (cost_val, accuracy_val) = _evaluate(x_train, y_train, batch_size)\n",
        "    print(\"Train metric:\")\n",
        "    print({\"accuracy\": accuracy_val, \"loss\": cost_val})\n",
        "    \n",
        "    (cost_val, accuracy_val) = _evaluate(x_test, y_test, batch_size)\n",
        "    print(\"Test metric:\")\n",
        "    print({\"accuracy\": accuracy_val, \"loss\": cost_val})\n",
        "\n",
        "\n",
        "  def predict():\n",
        "    df = _predict(x_test, ds.target_names, batch_size)\n",
        "    df.index = x_test_ds.index\n",
        "    ydata = ds.target_names[np.argmax(y_test, axis=1)]\n",
        "    df[\"ydata\"] = ydata\n",
        "    df[\"max_prob\"] = df.iloc[:, 0:10].apply(lambda x: x.max(), axis=1)\n",
        "    return df\n",
        "  \n",
        "  def plot_image(df_pred):\n",
        "    idx = df_pred.index.to_numpy()\n",
        "    images_labels_pred = list(zip(ds.images[idx], ds.target[idx], df_pred[\"ypred\"].to_numpy()))\n",
        "    for index, (image, label, pred) in enumerate(images_labels_pred[:10]):\n",
        "        plt.subplot(2, 5, index + 1)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "        plt.title('P:%i, D:%i' % (pred, label))\n",
        "\n",
        "\n",
        "  return (train, evaluate, predict, plot_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M7keRw4XYKm",
        "colab_type": "code",
        "outputId": "1808e0dd-86c0-4da0-835d-e85953ad35c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "(ex_train, ex_eval, ex_predict, plot_image) = ex()\n",
        "ex_train(1000)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0 \t| Loss = 313.19373 \t| Accuracy = 0.09375\n",
            "Iteration 200 \t| Loss = 7.1153274 \t| Accuracy = 0.984375\n",
            "Iteration 400 \t| Loss = 2.089248 \t| Accuracy = 0.9921875\n",
            "Iteration 600 \t| Loss = 0.6063839 \t| Accuracy = 1.0\n",
            "Iteration 800 \t| Loss = 0.28995538 \t| Accuracy = 1.0\n",
            "Iteration 1000 \t| Loss = 0.14840417 \t| Accuracy = 1.0\n",
            "Iteration 1200 \t| Loss = 0.10445489 \t| Accuracy = 1.0\n",
            "Iteration 1400 \t| Loss = 0.04633239 \t| Accuracy = 1.0\n",
            "Iteration 1600 \t| Loss = 0.013861453 \t| Accuracy = 1.0\n",
            "Iteration 1800 \t| Loss = 0.021195395 \t| Accuracy = 1.0\n",
            "Iteration 2000 \t| Loss = 0.022752827 \t| Accuracy = 1.0\n",
            "Iteration 2200 \t| Loss = 0.0099365935 \t| Accuracy = 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clG8Da9B7Cl2",
        "colab_type": "code",
        "outputId": "30d76dd7-a3f9-4c25-9407-032d1766255f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "ex_eval()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train metric:\n",
            "{'accuracy': 1.0, 'loss': 0.00012002384755760431}\n",
            "Test metric:\n",
            "{'accuracy': 0.9741071462631226, 'loss': 0.22702412605285643}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK9oMygO1yqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = ex_predict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPlJRTYig97x",
        "colab_type": "code",
        "outputId": "3f37784e-cd78-4c70-b7cb-a167046ed43f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "print(\"Correct prediction:\")\n",
        "df_correct = df.loc[df[\"ypred\"] == df[\"ydata\"]]\n",
        "df_correct"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct prediction:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>ypred</th>\n",
              "      <th>ydata</th>\n",
              "      <th>max_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1555</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1628</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.997</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.002</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>716</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>921</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.999</td>\n",
              "      <td>0.000</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0.999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>527 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0      1    2    3      4  ...      8      9  ypred  ydata  max_prob\n",
              "434   1.0  0.000  0.0  0.0  0.000  ...  0.000  0.000      0      0     1.000\n",
              "1555  1.0  0.000  0.0  0.0  0.000  ...  0.000  0.000      0      0     1.000\n",
              "532   0.0  0.000  0.0  0.0  0.000  ...  0.000  0.000      6      6     1.000\n",
              "1628  0.0  0.000  0.0  0.0  0.997  ...  0.000  0.002      4      4     0.997\n",
              "716   0.0  1.000  0.0  0.0  0.000  ...  0.000  0.000      1      1     1.000\n",
              "...   ...    ...  ...  ...    ...  ...    ...    ...    ...    ...       ...\n",
              "1196  0.0  0.000  0.0  0.0  0.000  ...  0.000  1.000      9      9     1.000\n",
              "921   0.0  0.000  0.0  0.0  0.000  ...  0.000  0.000      6      6     1.000\n",
              "611   0.0  0.000  0.0  0.0  0.000  ...  0.000  0.000      6      6     1.000\n",
              "1397  0.0  0.000  0.0  0.0  1.000  ...  0.000  0.000      4      4     1.000\n",
              "242   0.0  0.001  0.0  0.0  0.000  ...  0.999  0.000      8      8     0.999\n",
              "\n",
              "[527 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO_2YG5RhEvr",
        "colab_type": "code",
        "outputId": "677fc0e9-e41c-4ce6-8437-a5b3879c4b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "print(\"Wrong prediction:\")\n",
        "df_err = df.loc[df[\"ypred\"] != df[\"ydata\"]]\n",
        "df_err"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrong prediction:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>ypred</th>\n",
              "      <th>ydata</th>\n",
              "      <th>max_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1660</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.107</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.773</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>0.773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>678</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.937</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.062</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0.937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>0.004</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.216</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.779</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>0.779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1632</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.174</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.821</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>0.821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>0.002</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.098</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.899</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>0.899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1264</th>\n",
              "      <td>0.328</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.035</td>\n",
              "      <td>0.208</td>\n",
              "      <td>0.030</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.056</td>\n",
              "      <td>0.341</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0.341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1727</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.731</td>\n",
              "      <td>0.220</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.049</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1551</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.898</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.026</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.063</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0.898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1573</th>\n",
              "      <td>0.032</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.966</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1662</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.220</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>0.778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1553</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.998</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1571</th>\n",
              "      <td>0.324</td>\n",
              "      <td>0.026</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.540</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.074</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>0.540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.620</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.369</td>\n",
              "      <td>0.009</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>0.620</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0      1      2      3      4  ...      8      9  ypred  ydata  max_prob\n",
              "1660  0.000  0.000  0.000  0.000  0.107  ...  0.120  0.773      9      4     0.773\n",
              "678   0.000  0.000  0.000  0.000  0.937  ...  0.000  0.000      4      5     0.937\n",
              "421   0.004  0.000  0.000  0.000  0.000  ...  0.000  0.779      9      5     0.779\n",
              "1632  0.000  0.001  0.001  0.174  0.000  ...  0.000  0.821      9      3     0.821\n",
              "480   0.002  0.000  0.000  0.000  0.000  ...  0.000  0.899      9      7     0.899\n",
              "1264  0.328  0.002  0.000  0.000  0.035  ...  0.056  0.341      9      1     0.341\n",
              "1727  0.000  0.000  0.731  0.220  0.000  ...  0.049  0.000      2      3     0.731\n",
              "1551  0.000  0.898  0.012  0.000  0.026  ...  0.001  0.000      1      6     0.898\n",
              "1573  0.032  0.000  0.000  0.000  0.966  ...  0.000  0.000      4      0     0.966\n",
              "1662  0.001  0.000  0.000  0.000  0.001  ...  0.000  0.220      5      9     0.778\n",
              "1553  0.000  0.998  0.000  0.000  0.001  ...  0.000  0.000      1      8     0.998\n",
              "1571  0.324  0.026  0.000  0.000  0.011  ...  0.017  0.074      5      8     0.540\n",
              "1197  0.000  0.000  0.000  0.002  0.000  ...  0.369  0.009      5      8     0.620\n",
              "\n",
              "[13 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSGPr4g279Hx",
        "colab_type": "code",
        "outputId": "bf3aa23e-5805-4b66-dce1-60e2ef410830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "plot_image(df_err)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADOCAYAAACdDdHuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F17Gvez03R1",
        "colab_type": "code",
        "outputId": "bf0dcccf-0e63-4c65-a0c1-09923c25e597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "print(\"Correct prediction with high probability\")\n",
        "df_correct.loc[df[\"max_prob\"] >= 0.995]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct prediction with high probability\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>ypred</th>\n",
              "      <th>ydata</th>\n",
              "      <th>max_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1555</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1628</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.997</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.002</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>716</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>921</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.999</td>\n",
              "      <td>0.000</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0.999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>493 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0      1    2    3      4  ...      8      9  ypred  ydata  max_prob\n",
              "434   1.0  0.000  0.0  0.0  0.000  ...  0.000  0.000      0      0     1.000\n",
              "1555  1.0  0.000  0.0  0.0  0.000  ...  0.000  0.000      0      0     1.000\n",
              "532   0.0  0.000  0.0  0.0  0.000  ...  0.000  0.000      6      6     1.000\n",
              "1628  0.0  0.000  0.0  0.0  0.997  ...  0.000  0.002      4      4     0.997\n",
              "716   0.0  1.000  0.0  0.0  0.000  ...  0.000  0.000      1      1     1.000\n",
              "...   ...    ...  ...  ...    ...  ...    ...    ...    ...    ...       ...\n",
              "1196  0.0  0.000  0.0  0.0  0.000  ...  0.000  1.000      9      9     1.000\n",
              "921   0.0  0.000  0.0  0.0  0.000  ...  0.000  0.000      6      6     1.000\n",
              "611   0.0  0.000  0.0  0.0  0.000  ...  0.000  0.000      6      6     1.000\n",
              "1397  0.0  0.000  0.0  0.0  1.000  ...  0.000  0.000      4      4     1.000\n",
              "242   0.0  0.001  0.0  0.0  0.000  ...  0.999  0.000      8      8     0.999\n",
              "\n",
              "[493 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecrC9vsCEtgU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "7f506673-8f8f-4b82-9301-057dd12adba5"
      },
      "source": [
        "print(\"Wrong prediction with high probability\")\n",
        "df_err.loc[df[\"max_prob\"] >= 0.995]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrong prediction with high probability\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>ypred</th>\n",
              "      <th>ydata</th>\n",
              "      <th>max_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1553</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.998</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0      1    2    3      4    5  ...    7    8    9  ypred  ydata  max_prob\n",
              "1553  0.0  0.998  0.0  0.0  0.001  0.0  ...  0.0  0.0  0.0      1      8     0.998\n",
              "\n",
              "[1 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}